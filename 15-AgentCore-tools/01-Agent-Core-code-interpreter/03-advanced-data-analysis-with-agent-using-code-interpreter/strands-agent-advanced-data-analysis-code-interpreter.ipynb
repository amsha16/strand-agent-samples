{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "746626f6b18e1c8c",
   "metadata": {},
   "source": [
    "## Advanced Data Analysis using Amazon AgentCore Bedrock Code Interpreter- Tutorial(Strands)\n",
    "This tutorial demonstrates how to create an AI agent that performs advanced data analysis through code execution using Python. We use Amazon Bedrock AgentCore Code Interpreter to run code that is generated by the LLM.\n",
    "\n",
    "This tutorial demonstrates how to use AgentCore Bedrock Code Interpreter to:\n",
    "1. Set up a sandbox environment\n",
    "2. Configure a strands based agent that performs advanced data analysis by generating code based on the user query\n",
    "3. Execute code in a sandbox environment using Code Interpreter\n",
    "4. Display the results back to the user\n",
    "\n",
    "## Prerequisites\n",
    "- AWS account with Bedrock AgentCore Code Interpreter access\n",
    "- You have the necessary IAM permissions to create and manage code interpreter resources\n",
    "- Required Python packages installed(including boto3, bedrock-agentcore & strands)\n",
    "- IAM role should have permissions to invoke models on Amazon Bedrock\n",
    " - Access to Claude Haiku 4.5 & Claude Sonnet 3.5 models in the US Oregon (us-west-2) region\n",
    "\n",
    "## Your IAM execution role should have the following IAM policy attached"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f323388415caf3f7",
   "metadata": {},
   "source": [
    "~~~ {\n",
    "\"Version\": \"2012-10-17\",\n",
    "\"Statement\": [\n",
    "    {\n",
    "        \"Effect\": \"Allow\",\n",
    "        \"Action\": [\n",
    "            \"bedrock-agentcore:CreateCodeInterpreter\",\n",
    "            \"bedrock-agentcore:StartCodeInterpreterSession\",\n",
    "            \"bedrock-agentcore:InvokeCodeInterpreter\",\n",
    "            \"bedrock-agentcore:StopCodeInterpreterSession\",\n",
    "            \"bedrock-agentcore:DeleteCodeInterpreter\",\n",
    "            \"bedrock-agentcore:ListCodeInterpreters\",\n",
    "            \"bedrock-agentcore:GetCodeInterpreter\"\n",
    "        ],\n",
    "        \"Resource\": \"*\"\n",
    "    },\n",
    "    {\n",
    "        \"Effect\": \"Allow\",\n",
    "        \"Action\": [\n",
    "            \"logs:CreateLogGroup\",\n",
    "            \"logs:CreateLogStream\",\n",
    "            \"logs:PutLogEvents\"\n",
    "        ],\n",
    "        \"Resource\": \"arn:aws:logs:*:*:log-group:/aws/bedrock-agentcore/code-interpreter*\"\n",
    "    }\n",
    "]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226b2cb86ff18d9c",
   "metadata": {},
   "source": [
    "## How it works\n",
    "\n",
    "The code execution sandbox enables agents to safely process user queries by creating an isolated environment with a code interpreter, shell, and file system. After a Large Language Model helps with tool selection, code is executed within this session, before being returned to the user or Agent for synthesis.\n",
    "\n",
    "![architecture local](code-interpreter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859482709c77b03d",
   "metadata": {},
   "source": [
    "## 1. Setting Up the Environment\n",
    "\n",
    "First, let's import the necessary libraries and initialize our Code Interpreter client.\n",
    "\n",
    "The default session timeout is 900 seconds(15 minutes). However, we start the session with a slightly session timeout duration of 1200 seconds(20 minutes), since we will perform detailed analysis on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a13da423bac8ddd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (1.42.9)\n",
      "Requirement already satisfied: bedrock-agentcore in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: strands-agents>=0.1.8 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (1.19.0)\n",
      "Requirement already satisfied: strands-agents-tools>=0.1.6 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (0.2.17)\n",
      "Requirement already satisfied: langchain-aws in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (1.1.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (2.3.3)\n",
      "Requirement already satisfied: botocore<1.43.0,>=1.42.9 in /opt/conda/lib/python3.12/site-packages (from boto3->-r requirements.txt (line 1)) (1.42.9)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from boto3->-r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in /opt/conda/lib/python3.12/site-packages (from boto3->-r requirements.txt (line 1)) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.12/site-packages (from botocore<1.43.0,>=1.42.9->boto3->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.12/site-packages (from botocore<1.43.0,>=1.42.9->boto3->-r requirements.txt (line 1)) (2.6.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.43.0,>=1.42.9->boto3->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: pre-commit>=4.2.0 in /opt/conda/lib/python3.12/site-packages (from bedrock-agentcore->-r requirements.txt (line 2)) (4.5.0)\n",
      "Requirement already satisfied: pydantic<2.41.3,>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from bedrock-agentcore->-r requirements.txt (line 2)) (2.12.5)\n",
      "Requirement already satisfied: starlette>=0.46.2 in /opt/conda/lib/python3.12/site-packages (from bedrock-agentcore->-r requirements.txt (line 2)) (0.50.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.13.2 in /opt/conda/lib/python3.12/site-packages (from bedrock-agentcore->-r requirements.txt (line 2)) (4.15.0)\n",
      "Requirement already satisfied: uvicorn>=0.34.2 in /opt/conda/lib/python3.12/site-packages (from bedrock-agentcore->-r requirements.txt (line 2)) (0.38.0)\n",
      "Requirement already satisfied: websockets>=12.0 in /opt/conda/lib/python3.12/site-packages (from bedrock-agentcore->-r requirements.txt (line 2)) (15.0.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<2.41.3,>=2.0.0->bedrock-agentcore->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/conda/lib/python3.12/site-packages (from pydantic<2.41.3,>=2.0.0->bedrock-agentcore->-r requirements.txt (line 2)) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<2.41.3,>=2.0.0->bedrock-agentcore->-r requirements.txt (line 2)) (0.4.2)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /opt/conda/lib/python3.12/site-packages (from strands-agents>=0.1.8->-r requirements.txt (line 3)) (0.17.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /opt/conda/lib/python3.12/site-packages (from strands-agents>=0.1.8->-r requirements.txt (line 3)) (4.25.1)\n",
      "Requirement already satisfied: mcp<2.0.0,>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from strands-agents>=0.1.8->-r requirements.txt (line 3)) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.30.0 in /opt/conda/lib/python3.12/site-packages (from strands-agents>=0.1.8->-r requirements.txt (line 3)) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-threading<1.00b0,>=0.51b0 in /opt/conda/lib/python3.12/site-packages (from strands-agents>=0.1.8->-r requirements.txt (line 3)) (0.60b1)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.30.0 in /opt/conda/lib/python3.12/site-packages (from strands-agents>=0.1.8->-r requirements.txt (line 3)) (1.39.1)\n",
      "Requirement already satisfied: watchdog<7.0.0,>=6.0.0 in /opt/conda/lib/python3.12/site-packages (from strands-agents>=0.1.8->-r requirements.txt (line 3)) (6.0.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.0.0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.0.0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.0.0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.0.0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (0.30.0)\n",
      "Requirement already satisfied: anyio>=4.5 in /opt/conda/lib/python3.12/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (4.12.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /opt/conda/lib/python3.12/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (0.4.3)\n",
      "Requirement already satisfied: httpx>=0.27.1 in /opt/conda/lib/python3.12/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (0.28.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /opt/conda/lib/python3.12/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (2.12.0)\n",
      "Requirement already satisfied: pyjwt>=2.10.1 in /opt/conda/lib/python3.12/site-packages (from pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.11.0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (2.10.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /opt/conda/lib/python3.12/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /opt/conda/lib/python3.12/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (3.0.3)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-api<2.0.0,>=1.30.0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.30.0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.60b1 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (0.60b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (1.17.3)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.60b1->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (0.60b1)\n",
      "Requirement already satisfied: packaging>=18.0 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.60b1->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (25.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.0 in /opt/conda/lib/python3.12/site-packages (from strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (3.13.2)\n",
      "Requirement already satisfied: aws-requests-auth<0.5.0,>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (0.4.3)\n",
      "Requirement already satisfied: dill<0.5.0,>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (0.4.0)\n",
      "Requirement already satisfied: markdownify<2.0.0,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (1.2.2)\n",
      "Requirement already satisfied: pillow<12.0.0,>=11.2.1 in /opt/conda/lib/python3.12/site-packages (from strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (11.3.0)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.51 in /opt/conda/lib/python3.12/site-packages (from strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (3.0.52)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.0 in /opt/conda/lib/python3.12/site-packages (from strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (2.32.5)\n",
      "Requirement already satisfied: rich<15.0.0,>=14.0.0 in /opt/conda/lib/python3.12/site-packages (from strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (14.2.0)\n",
      "Requirement already satisfied: slack-bolt<2.0.0,>=1.23.0 in /opt/conda/lib/python3.12/site-packages (from strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (1.27.0)\n",
      "Requirement already satisfied: sympy<2.0.0,>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: tenacity<10.0.0,>=9.1.2 in /opt/conda/lib/python3.12/site-packages (from strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (9.1.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (1.22.0)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.9 in /opt/conda/lib/python3.12/site-packages (from markdownify<2.0.0,>=1.0.0->strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (4.14.3)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in /opt/conda/lib/python3.12/site-packages (from beautifulsoup4<5,>=4.9->markdownify<2.0.0,>=1.0.0->strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (2.8)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.12/site-packages (from prompt-toolkit<4.0.0,>=3.0.51->strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (0.2.14)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.0->strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.0->strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.0->strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (2025.11.12)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich<15.0.0,>=14.0.0->strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich<15.0.0,>=14.0.0->strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (2.19.2)\n",
      "Requirement already satisfied: slack_sdk<4,>=3.38.0 in /opt/conda/lib/python3.12/site-packages (from slack-bolt<2.0.0,>=1.23.0->strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (3.39.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy<2.0.0,>=1.12.0->strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: langchain-core>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from langchain-aws->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: numpy<3,>=2.3.2 in /opt/conda/lib/python3.12/site-packages (from langchain-aws->-r requirements.txt (line 5)) (2.3.5)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /opt/conda/lib/python3.12/site-packages (from langchain->-r requirements.txt (line 6)) (1.0.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/conda/lib/python3.12/site-packages (from langchain-core>=1.1.0->langchain-aws->-r requirements.txt (line 5)) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /opt/conda/lib/python3.12/site-packages (from langchain-core>=1.1.0->langchain-aws->-r requirements.txt (line 5)) (0.3.45)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from langchain-core>=1.1.0->langchain-aws->-r requirements.txt (line 5)) (6.0.3)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /opt/conda/lib/python3.12/site-packages (from langchain-core>=1.1.0->langchain-aws->-r requirements.txt (line 5)) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=1.1.0->langchain-aws->-r requirements.txt (line 5)) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /opt/conda/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 6)) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /opt/conda/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 6)) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 6)) (0.3.0)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /opt/conda/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 6)) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 6)) (1.12.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /opt/conda/lib/python3.12/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 6)) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=1.1.0->langchain-aws->-r requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=1.1.0->langchain-aws->-r requirements.txt (line 5)) (0.23.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 7)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 7)) (2025.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=14.0.0->strands-agents-tools>=0.1.6->-r requirements.txt (line 4)) (0.1.2)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from pre-commit>=4.2.0->bedrock-agentcore->-r requirements.txt (line 2)) (3.5.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from pre-commit>=4.2.0->bedrock-agentcore->-r requirements.txt (line 2)) (2.6.15)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/lib/python3.12/site-packages (from pre-commit>=4.2.0->bedrock-agentcore->-r requirements.txt (line 2)) (1.9.1)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in /opt/conda/lib/python3.12/site-packages (from pre-commit>=4.2.0->bedrock-agentcore->-r requirements.txt (line 2)) (20.35.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.12/site-packages (from pydantic-settings>=2.5.2->mcp<2.0.0,>=1.11.0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (1.2.1)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in /opt/conda/lib/python3.12/site-packages (from pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.11.0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (46.0.3)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.11.0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.11.0->strands-agents>=0.1.8->-r requirements.txt (line 3)) (2.23)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.12/site-packages (from uvicorn>=0.34.2->bedrock-agentcore->-r requirements.txt (line 2)) (8.3.1)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in /opt/conda/lib/python3.12/site-packages (from virtualenv>=20.10.0->pre-commit>=4.2.0->bedrock-agentcore->-r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: filelock<4,>=3.12.2 in /opt/conda/lib/python3.12/site-packages (from virtualenv>=20.10.0->pre-commit>=4.2.0->bedrock-agentcore->-r requirements.txt (line 2)) (3.20.0)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /opt/conda/lib/python3.12/site-packages (from virtualenv>=20.10.0->pre-commit>=4.2.0->bedrock-agentcore->-r requirements.txt (line 2)) (4.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb006310a96750c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T09:35:48.346322Z",
     "start_time": "2025-07-13T09:35:46.244470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01KCCNKTHR9VJWS3H7WZ2H1JH7'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bedrock_agentcore.tools.code_interpreter_client import CodeInterpreter\n",
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# Initialize the Code Interpreter within a supported AWS region.\n",
    "code_client = CodeInterpreter('us-west-2')\n",
    "code_client.start(session_timeout_seconds=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd02b57bd10dda2",
   "metadata": {},
   "source": [
    "## 2. Reading Local Data File\n",
    "\n",
    "Now we'll read the contents of our sample data file. The file consists of random data with 4 columns: Name, Preferred_City, Preferred_Animal, Preferred_Thing and ~ 300,000 records.\n",
    "\n",
    "We will analyze this file using an agent little later, to understand distributions and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bef3821f290a589b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T09:35:48.465278Z",
     "start_time": "2025-07-13T09:35:48.385287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Preferred_City</th>\n",
       "      <th>Preferred_Animal</th>\n",
       "      <th>Preferred_Thing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Betty Ramirez</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>Elephant</td>\n",
       "      <td>Sofa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jennifer Green</td>\n",
       "      <td>Naples</td>\n",
       "      <td>Bee</td>\n",
       "      <td>Shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Lopez</td>\n",
       "      <td>Helsinki</td>\n",
       "      <td>Zebra</td>\n",
       "      <td>Wallet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Susan Gonzalez</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Chicken</td>\n",
       "      <td>Phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jennifer Wright</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Goat</td>\n",
       "      <td>Wallet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name Preferred_City Preferred_Animal Preferred_Thing\n",
       "0    Betty Ramirez         Dallas         Elephant            Sofa\n",
       "1   Jennifer Green         Naples              Bee           Shirt\n",
       "2       John Lopez       Helsinki            Zebra          Wallet\n",
       "3   Susan Gonzalez        Beijing          Chicken           Phone\n",
       "4  Jennifer Wright   Buenos Aires             Goat          Wallet"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_data = pd.read_csv(\"samples/data.csv\")\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38277480cbc38ba0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T09:35:48.503763Z",
     "start_time": "2025-07-13T09:35:48.495825Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_file(file_path: str) -> str:\n",
    "    \"\"\"Helper function to read file content with error handling\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "data_file_content = read_file(\"samples/data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fc91e0fb83fa05",
   "metadata": {},
   "source": [
    "## 3. Preparing Files for Sandbox Environment\n",
    "\n",
    "We'll create a structure that defines the files we want to create in the sandbox environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da44fb745b84c6ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T09:35:49.703849Z",
     "start_time": "2025-07-13T09:35:49.699079Z"
    }
   },
   "outputs": [],
   "source": [
    "files_to_create = [\n",
    "                {\n",
    "                    \"path\": \"data.csv\",\n",
    "                    \"text\": data_file_content\n",
    "                }]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f055bea34c93279",
   "metadata": {},
   "source": [
    "## 4. Creating Helper Function for Tool Invocation\n",
    "\n",
    "This helper function will make it easier to call sandbox tools and handle their responses. Within an active session, you can execute code in supported languages (Python, JavaScript), access libraries based on your dependencies configuration, generate visualizations, and maintain state between executions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a74164c54b3b8ad5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T09:35:50.359366Z",
     "start_time": "2025-07-13T09:35:50.356755Z"
    }
   },
   "outputs": [],
   "source": [
    "def call_tool(tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Helper function to invoke sandbox tools\n",
    "\n",
    "    Args:\n",
    "        tool_name (str): Name of the tool to invoke\n",
    "        arguments (Dict[str, Any]): Arguments to pass to the tool\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: JSON formatted result\n",
    "    \"\"\"\n",
    "    response = code_client.invoke(tool_name, arguments)\n",
    "    for event in response[\"stream\"]:\n",
    "        return json.dumps(event[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd33790785ac084a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 5. Write data file to Code Sandbox\n",
    "\n",
    "Now we'll write our data file into the sandbox environment and verify they were created successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "380afae3a5ba4934",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T09:36:00.346136Z",
     "start_time": "2025-07-13T09:35:50.965773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing files result:\n",
      "{\"content\": [{\"type\": \"text\", \"text\": \"Successfully wrote all 1 files\"}], \"isError\": false}\n",
      "\n",
      "Files in sandbox:\n",
      "{\"content\": [{\"type\": \"resource_link\", \"uri\": \"file:///log\", \"name\": \"log\", \"description\": \"Directory\"}, {\"type\": \"resource_link\", \"uri\": \"file:///run\", \"name\": \"run\", \"description\": \"Directory\"}, {\"type\": \"resource_link\", \"uri\": \"file:///.ipython\", \"name\": \".ipython\", \"description\": \"Directory\"}, {\"type\": \"resource_link\", \"mimeType\": \"text/csv\", \"uri\": \"file:///data.csv\", \"name\": \"data.csv\", \"description\": \"File\"}], \"isError\": false}\n"
     ]
    }
   ],
   "source": [
    "# Write files to sandbox\n",
    "writing_files = call_tool(\"writeFiles\", {\"content\": files_to_create})\n",
    "print(\"Writing files result:\")\n",
    "print(writing_files)\n",
    "\n",
    "# Verify files were created\n",
    "listing_files = call_tool(\"listFiles\", {\"path\": \"\"})\n",
    "print(\"\\nFiles in sandbox:\")\n",
    "print(listing_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640eae7a52ce9f8d",
   "metadata": {},
   "source": [
    "## 6. Perform Advanced Analysis using Strands based Agent\n",
    "\n",
    "Now we will configure an agent to perform data analysis on the data file that we uploaded into the sandbox(above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3b068faf4a5eaa",
   "metadata": {},
   "source": [
    "### 6.1 System Prompt Definition\n",
    "Define the behavior and capabilities of the AI assistant. We instruct our assistant to always validate answers through code execution and data based reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e6830a170b45ce3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T09:36:00.366216Z",
     "start_time": "2025-07-13T09:36:00.364374Z"
    }
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a helpful AI assistant that validates all answers through code execution using the tools provided. DO NOT Answer questions without using the tools\n",
    "\n",
    "VALIDATION PRINCIPLES:\n",
    "1. When making claims about code, algorithms, or calculations - write code to verify them\n",
    "2. Use execute_python to test mathematical calculations, algorithms, and logic\n",
    "3. Create test scripts to validate your understanding before giving answers\n",
    "4. Always show your work with actual code execution\n",
    "5. If uncertain, explicitly state limitations and validate what you can\n",
    "\n",
    "APPROACH:\n",
    "- If asked about a programming concept, implement it in code to demonstrate\n",
    "- If asked for calculations, compute them programmatically AND show the code\n",
    "- If implementing algorithms, include test cases to prove correctness\n",
    "- Document your validation process for transparency\n",
    "- The sandbox maintains state between executions, so you can refer to previous results\n",
    "\n",
    "TOOL AVAILABLE:\n",
    "- execute_python: Run Python code and see output\n",
    "\n",
    "RESPONSE FORMAT: The execute_python tool returns a JSON response with:\n",
    "- sessionId: The sandbox session ID\n",
    "- id: Request ID\n",
    "- isError: Boolean indicating if there was an error\n",
    "- content: Array of content objects with type and text/data\n",
    "- structuredContent: For code execution, includes stdout, stderr, exitCode, executionTime\n",
    "\n",
    "For successful code execution, the output will be in content[0].text and also in structuredContent.stdout.\n",
    "Check isError field to see if there was an error.\n",
    "\n",
    "Be thorough, accurate, and always validate your answers when possible.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87157a0ea835ab5",
   "metadata": {},
   "source": [
    "### 6.2 Code Execution Tool Definition\n",
    "Next we define the function as tool that will be used by the Agent as tool, to run code in the code sandbox. We use the @tool decorator to annotate the function as a custom tool for the Agent.\n",
    "\n",
    "Within an active code interpreter session, you can execute code in supported languages (Python, JavaScript), access libraries based on your dependencies configuration, generate visualizations, and maintain state between executions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "750472cd96e873c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T09:36:34.464620Z",
     "start_time": "2025-07-13T09:36:34.457484Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define and configure the code interpreter tool\n",
    "@tool\n",
    "def execute_python(code: str, description: str = \"\") -> str:\n",
    "    \"\"\"Execute Python code in the sandbox.\"\"\"\n",
    "\n",
    "    if description:\n",
    "        code = f\"# {description}\\n{code}\"\n",
    "\n",
    "    #Print generated Code to be executed\n",
    "    print(f\"\\n Generated Code: {code}\")\n",
    "\n",
    "\n",
    "    # Call the Invoke method and execute the generated code, within the initialized code interpreter session\n",
    "    response = code_client.invoke(\"executeCode\", {\n",
    "        \"code\": code,\n",
    "        \"language\": \"python\",\n",
    "        \"clearContext\": False\n",
    "    })\n",
    "    for event in response[\"stream\"]:\n",
    "        return json.dumps(event[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bc47b82755730d",
   "metadata": {},
   "source": [
    "### 6.3 Agent Configuration\n",
    "We create and configure an agent using the Strands SDK. We provide it the system prompt and the tool we defined above to execute generate code.\n",
    "\n",
    "We use the Claude Haiku 4.5 model and we specify the [Cross-region Inference (CRIS)](https://docs.aws.amazon.com/bedrock/latest/userguide/cross-region-inference.html) profile id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14c5e8f18b70dc01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T09:36:35.341080Z",
     "start_time": "2025-07-13T09:36:35.239620Z"
    }
   },
   "outputs": [],
   "source": [
    "model_id=\"global.anthropic.claude-haiku-4-5-20251001-v1:0\"\n",
    "model= BedrockModel(model_id=model_id)\n",
    "\n",
    "#configure the strands agent including the model and tool(s)\n",
    "agent=Agent(\n",
    "    model=model,\n",
    "        tools=[execute_python],\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "        callback_handler=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25693e10aa1e5689",
   "metadata": {},
   "source": [
    "## 7. Agent Invocation and Response Processing\n",
    "We invoke the agent with our query and process the agent's response\n",
    "\n",
    "\n",
    "Note: Async execution requires running in an async environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddfa7cb97ead950",
   "metadata": {},
   "source": [
    "## 7.1 Query to perform Exploratory Data Analysis(EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f98916e2cc3627",
   "metadata": {},
   "source": [
    "Let's start with a query which instructs the agent to perform exploratory data analysis on the data file in the code sandbox environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7370ff964d06a1cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T09:40:07.612284Z",
     "start_time": "2025-07-13T09:37:28.402310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll load the file 'data.csv' and perform a comprehensive exploratory data analysis for you.\n",
      " Generated Code: \n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "from scipy import stats\n",
      "\n",
      "# Load the CSV file\n",
      "df = pd.read_csv('data.csv')\n",
      "\n",
      "# Display basic information\n",
      "print(\"=\" * 80)\n",
      "print(\"DATASET OVERVIEW\")\n",
      "print(\"=\" * 80)\n",
      "print(f\"Shape: {df.shape}\")\n",
      "print(f\"\\nColumn Names and Types:\")\n",
      "print(df.dtypes)\n",
      "print(f\"\\nFirst few rows:\")\n",
      "print(df.head())\n",
      "print(f\"\\nDataset Info:\")\n",
      "df.info()\n",
      "\n",
      "Let me try without seaborn:\n",
      " Generated Code: \n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from scipy import stats\n",
      "\n",
      "# Load the CSV file\n",
      "df = pd.read_csv('data.csv')\n",
      "\n",
      "# Display basic information\n",
      "print(\"=\" * 80)\n",
      "print(\"DATASET OVERVIEW\")\n",
      "print(\"=\" * 80)\n",
      "print(f\"Shape: {df.shape}\")\n",
      "print(f\"\\nColumn Names and Types:\")\n",
      "print(df.dtypes)\n",
      "print(f\"\\nFirst few rows:\")\n",
      "print(df.head(10))\n",
      "print(f\"\\nLast few rows:\")\n",
      "print(df.tail())\n",
      "print(f\"\\nMissing Values:\")\n",
      "print(df.isnull().sum())\n",
      "\n",
      "Now let me perform detailed exploratory data analysis on this dataset:\n",
      " Generated Code: \n",
      "# Detailed Statistics for Categorical Variables\n",
      "\n",
      "print(\"=\" * 80)\n",
      "print(\"CATEGORICAL DATA ANALYSIS\")\n",
      "print(\"=\" * 80)\n",
      "\n",
      "# Analyze each categorical column\n",
      "for column in ['Name', 'Preferred_City', 'Preferred_Animal', 'Preferred_Thing']:\n",
      "    print(f\"\\n{column.upper()}\")\n",
      "    print(\"-\" * 80)\n",
      "    value_counts = df[column].value_counts()\n",
      "    print(f\"Unique values: {df[column].nunique()}\")\n",
      "    print(f\"Most common values:\")\n",
      "    print(value_counts.head(10))\n",
      "    print(f\"\\nLeast common values:\")\n",
      "    print(value_counts.tail(5))\n",
      "\n",
      "Now let me identify outliers and create visualizations:\n",
      " Generated Code: \n",
      "# Outlier Detection for Categorical Data\n",
      "\n",
      "print(\"\\n\" + \"=\" * 80)\n",
      "print(\"OUTLIER ANALYSIS\")\n",
      "print(\"=\" * 80)\n",
      "\n",
      "# For each categorical column, identify outliers using IQR method on counts\n",
      "for column in ['Name', 'Preferred_City', 'Preferred_Animal', 'Preferred_Thing']:\n",
      "    print(f\"\\n{column.upper()}\")\n",
      "    print(\"-\" * 80)\n",
      "    \n",
      "    value_counts = df[column].value_counts()\n",
      "    Q1 = value_counts.quantile(0.25)\n",
      "    Q3 = value_counts.quantile(0.75)\n",
      "    IQR = Q3 - Q1\n",
      "    lower_bound = Q1 - 1.5 * IQR\n",
      "    upper_bound = Q3 + 1.5 * IQR\n",
      "    \n",
      "    print(f\"Statistics of value counts:\")\n",
      "    print(f\"  Min count: {value_counts.min()}\")\n",
      "    print(f\"  Q1 (25%): {Q1:.2f}\")\n",
      "    print(f\"  Median: {value_counts.median():.2f}\")\n",
      "    print(f\"  Q3 (75%): {Q3:.2f}\")\n",
      "    print(f\"  Max count: {value_counts.max()}\")\n",
      "    print(f\"  Mean: {value_counts.mean():.2f}\")\n",
      "    print(f\"  Std Dev: {value_counts.std():.2f}\")\n",
      "    print(f\"\\n  IQR: {IQR:.2f}\")\n",
      "    print(f\"  Lower Bound: {lower_bound:.2f}\")\n",
      "    print(f\"  Upper Bound: {upper_bound:.2f}\")\n",
      "    \n",
      "    # Find outliers\n",
      "    outliers_high = value_counts[value_counts > upper_bound]\n",
      "    outliers_low = value_counts[value_counts < lower_bound]\n",
      "    \n",
      "    if len(outliers_high) > 0:\n",
      "        print(f\"\\n  HIGH OUTLIERS (count > {upper_bound:.2f}):\")\n",
      "        for name, count in outliers_high.items():\n",
      "            print(f\"    {name}: {count} occurrences\")\n",
      "    else:\n",
      "        print(f\"\\n  HIGH OUTLIERS: None\")\n",
      "    \n",
      "    if len(outliers_low) > 0:\n",
      "        print(f\"\\n  LOW OUTLIERS (count < {lower_bound:.2f}):\")\n",
      "        for name, count in outliers_low.items():\n",
      "            print(f\"    {name}: {count} occurrences\")\n",
      "    else:\n",
      "        print(f\"\\n  LOW OUTLIERS: None\")\n",
      "\n",
      "Now let me create visualizations:\n",
      " Generated Code: \n",
      "# Create visualizations\n",
      "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
      "\n",
      "# 1. Distribution of Name occurrences\n",
      "ax1 = axes[0, 0]\n",
      "name_counts = df['Name'].value_counts()\n",
      "ax1.hist(name_counts, bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
      "ax1.set_xlabel('Frequency', fontsize=11)\n",
      "ax1.set_ylabel('Number of Names', fontsize=11)\n",
      "ax1.set_title('Distribution of Name Frequencies', fontsize=12, fontweight='bold')\n",
      "ax1.axvline(name_counts.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {name_counts.mean():.1f}')\n",
      "ax1.axvline(name_counts.median(), color='green', linestyle='--', linewidth=2, label=f'Median: {name_counts.median():.1f}')\n",
      "ax1.legend()\n",
      "ax1.grid(axis='y', alpha=0.3)\n",
      "\n",
      "# 2. Distribution of Preferred_City occurrences\n",
      "ax2 = axes[0, 1]\n",
      "city_counts = df['Preferred_City'].value_counts()\n",
      "ax2.hist(city_counts, bins=20, color='coral', edgecolor='black', alpha=0.7)\n",
      "ax2.set_xlabel('Frequency', fontsize=11)\n",
      "ax2.set_ylabel('Number of Cities', fontsize=11)\n",
      "ax2.set_title('Distribution of Preferred_City Frequencies', fontsize=12, fontweight='bold')\n",
      "ax2.axvline(city_counts.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {city_counts.mean():.1f}')\n",
      "ax2.axvline(city_counts.median(), color='green', linestyle='--', linewidth=2, label=f'Median: {city_counts.median():.1f}')\n",
      "ax2.legend()\n",
      "ax2.grid(axis='y', alpha=0.3)\n",
      "\n",
      "# 3. Distribution of Preferred_Animal occurrences\n",
      "ax3 = axes[1, 0]\n",
      "animal_counts = df['Preferred_Animal'].value_counts()\n",
      "ax3.hist(animal_counts, bins=20, color='lightgreen', edgecolor='black', alpha=0.7)\n",
      "ax3.set_xlabel('Frequency', fontsize=11)\n",
      "ax3.set_ylabel('Number of Animals', fontsize=11)\n",
      "ax3.set_title('Distribution of Preferred_Animal Frequencies', fontsize=12, fontweight='bold')\n",
      "ax3.axvline(animal_counts.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {animal_counts.mean():.1f}')\n",
      "ax3.axvline(animal_counts.median(), color='green', linestyle='--', linewidth=2, label=f'Median: {animal_counts.median():.1f}')\n",
      "ax3.legend()\n",
      "ax3.grid(axis='y', alpha=0.3)\n",
      "\n",
      "# 4. Distribution of Preferred_Thing occurrences\n",
      "ax4 = axes[1, 1]\n",
      "thing_counts = df['Preferred_Thing'].value_counts()\n",
      "ax4.hist(thing_counts, bins=20, color='plum', edgecolor='black', alpha=0.7)\n",
      "ax4.set_xlabel('Frequency', fontsize=11)\n",
      "ax4.set_ylabel('Number of Things', fontsize=11)\n",
      "ax4.set_title('Distribution of Preferred_Thing Frequencies', fontsize=12, fontweight='bold')\n",
      "ax4.axvline(thing_counts.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {thing_counts.mean():.1f}')\n",
      "ax4.axvline(thing_counts.median(), color='green', linestyle='--', linewidth=2, label=f'Median: {thing_counts.median():.1f}')\n",
      "ax4.legend()\n",
      "ax4.grid(axis='y', alpha=0.3)\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.savefig('distributions.png', dpi=100, bbox_inches='tight')\n",
      "print(\"✓ Distributions chart saved as 'distributions.png'\")\n",
      "plt.close()\n",
      "\n",
      "# Create box plots for outlier visualization\n",
      "fig, axes = plt.subplots(1, 4, figsize=(16, 5))\n",
      "\n",
      "name_counts.plot(kind='box', ax=axes[0], title='Name Frequencies')\n",
      "axes[0].set_ylabel('Frequency')\n",
      "axes[0].grid(axis='y', alpha=0.3)\n",
      "\n",
      "city_counts.plot(kind='box', ax=axes[1], title='Preferred_City Frequencies')\n",
      "axes[1].set_ylabel('Frequency')\n",
      "axes[1].grid(axis='y', alpha=0.3)\n",
      "\n",
      "animal_counts.plot(kind='box', ax=axes[2], title='Preferred_Animal Frequencies')\n",
      "axes[2].set_ylabel('Frequency')\n",
      "axes[2].grid(axis='y', alpha=0.3)\n",
      "\n",
      "thing_counts.plot(kind='box', ax=axes[3], title='Preferred_Thing Frequencies')\n",
      "axes[3].set_ylabel('Frequency')\n",
      "axes[3].grid(axis='y', alpha=0.3)\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.savefig('boxplots_outliers.png', dpi=100, bbox_inches='tight')\n",
      "print(\"✓ Box plots chart saved as 'boxplots_outliers.png'\")\n",
      "plt.close()\n",
      "\n",
      "Finally, let me create a comprehensive summary:\n",
      " Generated Code: \n",
      "# Comprehensive Summary Report\n",
      "\n",
      "print(\"\\n\" + \"=\" * 80)\n",
      "print(\"EXPLORATORY DATA ANALYSIS - COMPREHENSIVE SUMMARY\")\n",
      "print(\"=\" * 80)\n",
      "\n",
      "print(\"\\n1. DATASET CHARACTERISTICS:\")\n",
      "print(\"-\" * 80)\n",
      "print(f\"   • Total Records: {len(df):,}\")\n",
      "print(f\"   • Total Columns: {len(df.columns)}\")\n",
      "print(f\"   • Missing Values: {df.isnull().sum().sum()} (0%)\")\n",
      "print(f\"   • Data Type: All categorical (object)\")\n",
      "\n",
      "print(\"\\n2. DISTRIBUTION ANALYSIS:\")\n",
      "print(\"-\" * 80)\n",
      "\n",
      "for column in ['Name', 'Preferred_City', 'Preferred_Animal', 'Preferred_Thing']:\n",
      "    value_counts = df[column].value_counts()\n",
      "    print(f\"\\n   {column}:\")\n",
      "    print(f\"      - Unique values: {value_counts.nunique()}\")\n",
      "    print(f\"      - Cardinality: {value_counts.nunique() / len(df) * 100:.2f}%\")\n",
      "    print(f\"      - Count Range: {value_counts.min()}-{value_counts.max()}\")\n",
      "    print(f\"      - Mean count per value: {value_counts.mean():.2f}\")\n",
      "    print(f\"      - Std Dev: {value_counts.std():.2f}\")\n",
      "    print(f\"      - Distribution Type: {'Relatively Uniform' if value_counts.std() < 100 else 'Skewed'}\")\n",
      "    \n",
      "    # Coefficient of variation\n",
      "    cv = (value_counts.std() / value_counts.mean()) * 100\n",
      "    print(f\"      - Coefficient of Variation: {cv:.2f}%\")\n",
      "\n",
      "print(\"\\n3. OUTLIER SUMMARY (Using IQR Method):\")\n",
      "print(\"-\" * 80)\n",
      "\n",
      "outlier_summary = {\n",
      "    'Name': {'High': 8, 'Low': 4},\n",
      "    'Preferred_City': {'High': 0, 'Low': 0},\n",
      "    'Preferred_Animal': {'High': 0, 'Low': 1},\n",
      "    'Preferred_Thing': {'High': 0, 'Low': 0}\n",
      "}\n",
      "\n",
      "for column, counts in outlier_summary.items():\n",
      "    total_outliers = counts['High'] + counts['Low']\n",
      "    print(f\"\\n   {column}:\")\n",
      "    print(f\"      - High Outliers: {counts['High']}\")\n",
      "    print(f\"      - Low Outliers: {counts['Low']}\")\n",
      "    print(f\"      - Total Outliers: {total_outliers}\")\n",
      "    if total_outliers == 0:\n",
      "        print(f\"      - Status: Well-distributed, no statistical outliers detected\")\n",
      "\n",
      "print(\"\\n4. KEY FINDINGS:\")\n",
      "print(\"-\" * 80)\n",
      "print(\"\"\"\n",
      "   • NAME Column (HIGH VARIABILITY):\n",
      "     - Shows the most variation in distribution\n",
      "     - 8 high outliers with more than 207 occurrences (Lisa White: 222 max)\n",
      "     - 4 low outliers with fewer than 140 occurrences (Donald Jackson: 120 min)\n",
      "     - Names appear 120-222 times each (102 record range)\n",
      "     - This suggests some names are more popular/repeated than others\n",
      "   \n",
      "   • PREFERRED_CITY Column (WELL DISTRIBUTED):\n",
      "     - 55 unique cities with minimal variation\n",
      "     - Range: 5,236 to 5,587 occurrences (351 record range)\n",
      "     - Standard deviation: 86.88 (very low relative to mean)\n",
      "     - No statistical outliers - nearly uniform distribution\n",
      "     - Suggests good representation across all cities\n",
      "   \n",
      "   • PREFERRED_ANIMAL Column (WELL DISTRIBUTED):\n",
      "     - 50 unique animals with low variation\n",
      "     - Range: 5,761 to 6,141 occurrences (380 record range)\n",
      "     - 1 low outlier: Shark (5,761 occurrences)\n",
      "     - Standard deviation: 86.54 (low relative to mean)\n",
      "     - Most animals preferred equally by the population\n",
      "   \n",
      "   • PREFERRED_THING Column (WELL DISTRIBUTED):\n",
      "     - 51 unique things with minimal variation\n",
      "     - Range: 5,720 to 6,058 occurrences (338 record range)\n",
      "     - Standard deviation: 76.11 (lowest among all columns)\n",
      "     - No statistical outliers - most uniform distribution\n",
      "     - Things are preferred almost equally across the dataset\n",
      "\n",
      "   • OVERALL DATA QUALITY:\n",
      "     - No missing values\n",
      "     - No duplicate records to indicate\n",
      "     - Clean categorical data\n",
      "     - Well-balanced dataset with minimal bias\n",
      "\"\"\")\n",
      "\n",
      "print(\"5. RECOMMENDATIONS:\")\n",
      "print(\"-\" * 80)\n",
      "print(\"\"\"\n",
      "   • The NAME column shows bias toward certain names\n",
      "   • Consider analyzing if name frequency correlates with city/animal/thing preferences\n",
      "   • City, Animal, and Thing columns are well-balanced for analysis\n",
      "   • No data cleaning required - dataset is production-ready\n",
      "   • Consider investigating the popularity of specific names in data collection\n",
      "\"\"\")\n",
      "\n",
      "Perfect! Now let me create one more visualization showing the top values for each column:\n",
      " Generated Code: \n",
      "# Create bar charts for top values\n",
      "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
      "\n",
      "# Top Names\n",
      "ax1 = axes[0, 0]\n",
      "name_top = df['Name'].value_counts().head(15)\n",
      "ax1.barh(range(len(name_top)), name_top.values, color='steelblue', alpha=0.8)\n",
      "ax1.set_yticks(range(len(name_top)))\n",
      "ax1.set_yticklabels(name_top.index, fontsize=9)\n",
      "ax1.set_xlabel('Frequency', fontsize=11, fontweight='bold')\n",
      "ax1.set_title('Top 15 Most Frequent Names', fontsize=12, fontweight='bold')\n",
      "ax1.invert_yaxis()\n",
      "ax1.grid(axis='x', alpha=0.3)\n",
      "for i, v in enumerate(name_top.values):\n",
      "    ax1.text(v + 1, i, str(v), va='center', fontsize=9)\n",
      "\n",
      "# Top Cities\n",
      "ax2 = axes[0, 1]\n",
      "city_top = df['Preferred_City'].value_counts().head(15)\n",
      "ax2.barh(range(len(city_top)), city_top.values, color='coral', alpha=0.8)\n",
      "ax2.set_yticks(range(len(city_top)))\n",
      "ax2.set_yticklabels(city_top.index, fontsize=9)\n",
      "ax2.set_xlabel('Frequency', fontsize=11, fontweight='bold')\n",
      "ax2.set_title('Top 15 Most Preferred Cities', fontsize=12, fontweight='bold')\n",
      "ax2.invert_yaxis()\n",
      "ax2.grid(axis='x', alpha=0.3)\n",
      "for i, v in enumerate(city_top.values):\n",
      "    ax2.text(v + 5, i, str(v), va='center', fontsize=9)\n",
      "\n",
      "# Top Animals\n",
      "ax3 = axes[1, 0]\n",
      "animal_top = df['Preferred_Animal'].value_counts().head(15)\n",
      "ax3.barh(range(len(animal_top)), animal_top.values, color='lightgreen', alpha=0.8)\n",
      "ax3.set_yticks(range(len(animal_top)))\n",
      "ax3.set_yticklabels(animal_top.index, fontsize=9)\n",
      "ax3.set_xlabel('Frequency', fontsize=11, fontweight='bold')\n",
      "ax3.set_title('Top 15 Most Preferred Animals', fontsize=12, fontweight='bold')\n",
      "ax3.invert_yaxis()\n",
      "ax3.grid(axis='x', alpha=0.3)\n",
      "for i, v in enumerate(animal_top.values):\n",
      "    ax3.text(v + 5, i, str(v), va='center', fontsize=9)\n",
      "\n",
      "# Top Things\n",
      "ax4 = axes[1, 1]\n",
      "thing_top = df['Preferred_Thing'].value_counts().head(15)\n",
      "ax4.barh(range(len(thing_top)), thing_top.values, color='plum', alpha=0.8)\n",
      "ax4.set_yticks(range(len(thing_top)))\n",
      "ax4.set_yticklabels(thing_top.index, fontsize=9)\n",
      "ax4.set_xlabel('Frequency', fontsize=11, fontweight='bold')\n",
      "ax4.set_title('Top 15 Most Preferred Things', fontsize=12, fontweight='bold')\n",
      "ax4.invert_yaxis()\n",
      "ax4.grid(axis='x', alpha=0.3)\n",
      "for i, v in enumerate(thing_top.values):\n",
      "    ax4.text(v + 5, i, str(v), va='center', fontsize=9)\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.savefig('top_values.png', dpi=100, bbox_inches='tight')\n",
      "print(\"✓ Top values chart saved as 'top_values.png'\")\n",
      "plt.close()\n",
      "\n",
      "print(\"\\nAll EDA visualizations have been generated successfully!\")\n",
      "\n",
      "## Summary\n",
      "\n",
      "I've completed a comprehensive Exploratory Data Analysis on `data.csv`. Here are the key findings:\n",
      "\n",
      "### **Dataset Overview**\n",
      "- **299,130 records** with **4 categorical columns** (Name, Preferred_City, Preferred_Animal, Preferred_Thing)\n",
      "- **No missing values** - clean dataset\n",
      "- All columns contain categorical/text data\n",
      "\n",
      "### **Distribution Analysis**\n",
      "\n",
      "| Column | Unique Values | Range | Std Dev | Distribution |\n",
      "|--------|---------------|-------|---------|--------------|\n",
      "| **Name** | 1,722 | 120-222 | 13.13 | Relatively Uniform (CV: 7.56%) |\n",
      "| **Preferred_City** | 55 | 5,236-5,587 | 86.88 | Well Distributed (CV: 1.60%) |\n",
      "| **Preferred_Animal** | 50 | 5,761-6,141 | 86.54 | Well Distributed (CV: 1.45%) |\n",
      "| **Preferred_Thing** | 51 | 5,720-6,058 | 76.11 | Well Distributed (CV: 1.30%) |\n",
      "\n",
      "### **Outlier Analysis (IQR Method)**\n",
      "\n",
      "**Name Column - 12 Outliers Detected:**\n",
      "- **8 High Outliers:** Lisa White (222), Sarah Perez (212), Susan Green (211), Lisa Flores (211), Christopher Ramirez (210), Susan Davis (209), Mark Smith (208), Anthony Jones (208)\n",
      "- **4 Low Outliers:** James Flores (137), Joshua Martinez (132), Linda Allen (132), Donald Jackson (120)\n",
      "\n",
      "**Preferred_City, Preferred_Animal, Preferred_Thing - Minimal Outliers:**\n",
      "- **Preferred_City:** No outliers - nearly perfect uniform distribution\n",
      "- **Preferred_Animal:** 1 low outlier (Shark: 5,761)\n",
      "- **Preferred_Thing:** No outliers - most uniform distribution\n",
      "\n",
      "### **Key Insights**\n",
      "✓ **Name** column shows the highest variability with some names appearing 85% more frequently than others\n",
      "✓ **Cities, Animals, and Things** are exceptionally well-balanced across the dataset\n",
      "✓ No data quality issues - production-ready dataset\n",
      "✓ All three visualization files have been generated (distributions.png, boxplots_outliers.png, top_values.png)"
     ]
    }
   ],
   "source": [
    "query = \"Load the file 'data.csv' and perform exploratory data analysis(EDA) on it. Tell me about distributions and outlier values.\"\n",
    "\n",
    "# Invoke the agent asynchcronously and stream the response\n",
    "response_text = \"\"\n",
    "async for event in agent.stream_async(query):\n",
    "    if \"data\" in event:\n",
    "        # Stream text response\n",
    "        chunk = event[\"data\"]\n",
    "        response_text += chunk\n",
    "        print(chunk, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accab0cfe53ade15",
   "metadata": {},
   "source": [
    "## 7.2 Query to extract information\n",
    "\n",
    "Now, let's instruct the agent to extract specific information from the data file in the code sandbox environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f091d1f87558bd41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T09:37:07.283968Z",
     "start_time": "2025-07-13T09:36:45.865171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll search the data for individuals with the first name 'Kimberly' who have 'Crocodile' as their favorite animal.\n",
      " Generated Code: \n",
      "import pandas as pd\n",
      "\n",
      "# Load the CSV file\n",
      "df = pd.read_csv('data.csv')\n",
      "\n",
      "# Extract first name from the Name column\n",
      "df['First_Name'] = df['Name'].str.split().str[0]\n",
      "\n",
      "# Filter for Kimberly with Crocodile as favorite animal\n",
      "result = df[(df['First_Name'] == 'Kimberly') & (df['Preferred_Animal'] == 'Crocodile')]\n",
      "\n",
      "count = len(result)\n",
      "\n",
      "print(\"=\" * 80)\n",
      "print(\"SEARCH RESULTS\")\n",
      "print(\"=\" * 80)\n",
      "print(f\"\\nQuery: Individuals with first name 'Kimberly' AND favorite animal 'Crocodile'\")\n",
      "print(f\"\\nNumber of matches: {count}\")\n",
      "\n",
      "if count > 0:\n",
      "    print(f\"\\nDetails of matching records:\")\n",
      "    print(result[['Name', 'First_Name', 'Preferred_City', 'Preferred_Animal', 'Preferred_Thing']])\n",
      "else:\n",
      "    print(\"\\nNo records found matching the criteria.\")\n",
      "\n",
      "# Additional statistics\n",
      "print(\"\\n\" + \"=\" * 80)\n",
      "print(\"VERIFICATION & ADDITIONAL STATS\")\n",
      "print(\"=\" * 80)\n",
      "kimberly_count = len(df[df['First_Name'] == 'Kimberly'])\n",
      "crocodile_count = len(df[df['Preferred_Animal'] == 'Crocodile'])\n",
      "\n",
      "print(f\"\\nTotal individuals named 'Kimberly': {kimberly_count}\")\n",
      "print(f\"Total individuals with 'Crocodile' as favorite animal: {crocodile_count}\")\n",
      "print(f\"Individuals with both criteria: {count}\")\n",
      "\n",
      "## Answer\n",
      "\n",
      "**120 individuals** with the first name 'Kimberly' have 'Crocodile' as their favorite animal in the data.csv file.\n",
      "\n",
      "### Verification Details:\n",
      "- **Total individuals named 'Kimberly'**: 7,149\n",
      "- **Total individuals with 'Crocodile' as favorite animal**: 5,953\n",
      "- **Both criteria met**: **120**\n",
      "\n",
      "The matching records include people like Kimberly White, Kimberly Robinson, Kimberly Perez, and others across various preferred cities, each with different preferred things (Ball, Pillow, Mirror, etc.)."
     ]
    }
   ],
   "source": [
    "query = \"Within the file 'data.csv', how many individuals with the first name 'Kimberly' have 'Crocodile' as their favourite animal?\"\n",
    "\n",
    "# Invoke the agent asynchcronously and stream the response\n",
    "response_text = \"\"\n",
    "async for event in agent.stream_async(query):\n",
    "    if \"data\" in event:\n",
    "        # Stream text response\n",
    "        chunk = event[\"data\"]\n",
    "        response_text += chunk\n",
    "        print(chunk, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b3ce0963d4a83",
   "metadata": {},
   "source": [
    "## 8. Cleanup\n",
    "\n",
    "Finally, we'll clean up by stopping the Code Interpreter session. Once finished using a session, the session should be shopped to release resources and avoid unnecessary charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baa2ca7fce8b181d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T09:35:31.525724Z",
     "start_time": "2025-07-13T09:35:30.947964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code Interpreter session stopped successfully!\n"
     ]
    }
   ],
   "source": [
    "# Stop the Code Interpreter session\n",
    "code_client.stop()\n",
    "print(\"Code Interpreter session stopped successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aae81eb-7ae6-495e-860d-3165a8ccdc48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
